# Confusion Matrix for delta and basic models

## Delta model confusion matrix

```{r}
library(caret)
library(dplyr)

set.seed(123) # Assurer la reproductibilité

# Préparer les données (s'assurer que `data_merlan` est ton DataFrame)
model_data <- data_merlan %>% select(-c(Surface, Abundance))

# Diviser en ensemble d'entraînement et de test
index <- createDataPartition(model_data$Density, p = 0.8, list = FALSE)
train_data <- model_data[index, ]
test_data <- model_data[-index, ]

# Entraîner le modèle sur l'ensemble d'entraînement
trained_model <- train_delta_model(train_data, "Density")  # Assure-toi que cette fonction existe

# Prédire sur l'ensemble de test
predictions <- predict_delta_model(trained_model, test_data %>% select(-Density))

# Discrétiser les prédictions et les valeurs réelles
threshold <- 0.1
predicted_classes <- ifelse(predictions < threshold, '<0.1', '>=0.1')
true_classes <- ifelse(test_data$Density < threshold, '<0.1', '>=0.1')

# Créer la matrice de confusion
delta_conf_matrix <- table(Predicted = predicted_classes, True = true_classes)

# Afficher la matrice de confusion
print(delta_conf_matrix)

# Calculer la précision de la classification
accuracy <- sum(diag(delta_conf_matrix)) / sum(delta_conf_matrix)
print(paste("Accuracy:", accuracy))
```

## Basic BRT model

```{r}
library(caret)
library(xgboost)
library(dplyr)

set.seed(123)

# On teste avec la même base exactement que celle utilisée pour le modèle delta

# On transforme en numeric

# S'assurer que toutes les colonnes à l'exception de 'Density' sont numériques
train_matrix <- as.matrix(sapply(train_data[, -which(names(train_data) == "Density")], as.numeric))
test_matrix <- as.matrix(sapply(test_data[, -which(names(test_data) == "Density")], as.numeric))

train_labels <- as.numeric(train_data$Density)
test_labels <- as.numeric(test_data$Density)


# Définition des paramètres pour xgboost
params <- list(
  booster = "gbtree",
  objective = "reg:squarederror",
  eta = 0.3,
  max_depth = 6,
  subsample = 0.75
)

# Entraînement du modèle BRT
xgboost_model <- xgboost(
  data = train_matrix,
  label = train_labels,
  params = params,
  nrounds = 100, # Le nombre d'arbres, tu peux choisir un autre nombre ou utiliser une validation croisée pour le déterminer
  verbose = 0  # pour éviter trop d'impression dans la console
)

# Faire des prédictions sur l'ensemble de test
xgb_predictions <- predict(xgboost_model, newdata = test_matrix)

# Discrétiser les prédictions et les valeurs réelles pour créer la matrice de confusion
xgb_predicted_classes <- ifelse(xgb_predictions < 0.1, '<0.1', '>=0.1')
true_classes <- ifelse(test_labels < 0.1, '<0.1', '>=0.1')

# Créer la matrice de confusion pour le modèle xgboost
xgb_conf_matrix <- table(Predicted = xgb_predicted_classes, True = true_classes)

# Afficher la matrice de confusion
print(xgb_conf_matrix)

# Calculer la précision pour le modèle xgboost
xgb_accuracy <- sum(diag(xgb_conf_matrix)) / sum(xgb_conf_matrix)
print(paste("Accuracy of xgboost model:", xgb_accuracy))
```

Plotting delta model confusion matrix

```{r}
library(ggplot2)
library(reshape2)  # pour utiliser melt()

# Convertir la matrice de confusion en dataframe
delta_conf_df <- as.data.frame.matrix(delta_conf_matrix)
delta_conf_df <- cbind(True = rownames(delta_conf_df), melt(delta_conf_df))
names(delta_conf_df) <- c("True", "Predicted", "Count")

# Créer un plot de heatmap pour Delta
ggplot(delta_conf_df, aes(x = Predicted, y = True, fill = Count)) +
  geom_tile(color = "white") +  # Bordures blanches pour les tuiles
  scale_fill_gradient(low = "blue", high = "red") +  # Utiliser un gradient de couleur foncé
  geom_text(aes(label = Count), color = "white", size = 6) +  # Ajouter des valeurs avec du texte blanc
  labs(title = "Matrice de confusion - Modèle Delta", x = "Valeur prédite", y = "Valeur réelle") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plotting the classic brt model matrix

```{r}
# Convertir la matrice de confusion en dataframe
xgb_conf_df <- as.data.frame.matrix(xgb_conf_matrix)
xgb_conf_df <- cbind(True = rownames(xgb_conf_df), melt(xgb_conf_df))
names(xgb_conf_df) <- c("True", "Predicted", "Count")

# Créer un plot de heatmap pour XGBoost
ggplot(xgb_conf_df, aes(x = Predicted, y = True, fill = Count)) +
  geom_tile(color = "white") +  # Bordures blanches pour les tuiles
  geom_text(aes(label = Count), color = "white", size = 6) +  # Ajouter des valeurs avec du texte blanc
  scale_fill_gradient(low = "blue", high = "red") +  # Utiliser un gradient de couleur foncé
  labs(title = "Matrice de confusion - Modèle XGBoost basique", x = "Valeur prédite", y = "Valeur réelle") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
